{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reward Modeling Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import urllib\n",
    "\n",
    "import lxml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sklearn\n",
    "import torch\n",
    "import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from langdetect import detect\n",
    "from lxml import html\n",
    "from scipy.stats import entropy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import (AutoModelForCausalLM, AutoTokenizer,\n",
    "                          GPTNeoXForSequenceClassification)\n",
    "from trl import (AutoModelForCausalLMWithValueHead, PPOConfig, PPOTrainer,\n",
    "                 create_reference_model)\n",
    "from trl.core import respond_to_batch\n",
    "\n",
    "from secret import S2_API_KEY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import load_survey\n",
    "\n",
    "questions, options, responses = load_survey()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b206c824d3a5adc396c40508e36692db66c2f4c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36d3a036cb8ea3b8520909ca083e785c710725d8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1bb5098945768be2debae1549305d0564c23879f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1e2c2d7c92ceba09939e53f1db8f3eba0ddaebdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2a1e2230ae32b9ad91e6cf66c1f437b9236817b5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430237</th>\n",
       "      <td>dd4e525afd450dad714188751fbf214ae2a14942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430238</th>\n",
       "      <td>bc5e3a98ab711f4ce0871ba8cae51a705b5d55b2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430239</th>\n",
       "      <td>d3f27e6b02879ad978fbdd0b2265eec1231856f6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430240</th>\n",
       "      <td>c4a608382748aa2b4949ed8cc06c6bb614b6fcc4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430241</th>\n",
       "      <td>7ddff674789b4d32ca01ed71365ea0991fe43c0c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>430242 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              id\n",
       "0       b206c824d3a5adc396c40508e36692db66c2f4c0\n",
       "1       36d3a036cb8ea3b8520909ca083e785c710725d8\n",
       "2       1bb5098945768be2debae1549305d0564c23879f\n",
       "3       1e2c2d7c92ceba09939e53f1db8f3eba0ddaebdb\n",
       "4       2a1e2230ae32b9ad91e6cf66c1f437b9236817b5\n",
       "...                                          ...\n",
       "430237  dd4e525afd450dad714188751fbf214ae2a14942\n",
       "430238  bc5e3a98ab711f4ce0871ba8cae51a705b5d55b2\n",
       "430239  d3f27e6b02879ad978fbdd0b2265eec1231856f6\n",
       "430240  c4a608382748aa2b4949ed8cc06c6bb614b6fcc4\n",
       "430241  7ddff674789b4d32ca01ed71365ea0991fe43c0c\n",
       "\n",
       "[430242 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data import fetch_paper_ids\n",
    "\n",
    "ids = fetch_paper_ids(questions, load=True)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Woman's essential \"nature\" : a classical, comm...</td>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Unbearable Coldness of Female Being: Women...</td>\n",
       "      <td>1998</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Becoming an academic: Writing the self via Fou...</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Also about Creative Motive in\"Wild Grass\"by Lu...</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perspektif Muhammad Sa‘Îd Al-Asymâwî tentang H...</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262190</th>\n",
       "      <td>Abortion: what is the good? : developing a dee...</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262191</th>\n",
       "      <td>Music, Mind, and Morality: Arousing the Body P...</td>\n",
       "      <td>2008</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262192</th>\n",
       "      <td>Autonomy, taking one's choices to be good, and...</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262193</th>\n",
       "      <td>Particularism and pleasure\\nBook synopsis: Par...</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262194</th>\n",
       "      <td>On the Structure of Rationality in the Thought...</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262195 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  year  citations\n",
       "0       Woman's essential \"nature\" : a classical, comm...  1997          1\n",
       "1       The Unbearable Coldness of Female Being: Women...  1998         39\n",
       "2       Becoming an academic: Writing the self via Fou...  2012          0\n",
       "3       Also about Creative Motive in\"Wild Grass\"by Lu...  2007          0\n",
       "4       Perspektif Muhammad Sa‘Îd Al-Asymâwî tentang H...  2009          0\n",
       "...                                                   ...   ...        ...\n",
       "262190  Abortion: what is the good? : developing a dee...  2008          0\n",
       "262191  Music, Mind, and Morality: Arousing the Body P...  2008         11\n",
       "262192  Autonomy, taking one's choices to be good, and...  2008          7\n",
       "262193  Particularism and pleasure\\nBook synopsis: Par...  2008          2\n",
       "262194  On the Structure of Rationality in the Thought...  2012          0\n",
       "\n",
       "[262195 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data import fetch_abstracts\n",
    "\n",
    "data = fetch_abstracts(ids, load=True)\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import load_tokenizer, load_base_model\n",
    "\n",
    "model_name = \"EleutherAI/pythia-70m-deduped\"\n",
    "tokenizer = load_tokenizer(model_name)\n",
    "base_model = load_base_model(tokenizer, model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import get_embeddings\n",
    "\n",
    "texts = data[\"text\"].values.tolist()\n",
    "embeddings = get_embeddings(texts, base_model, tokenizer, device=device, load=True)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10807, 237322)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import measure_similarity\n",
    "\n",
    "similarities = measure_similarity(embeddings, data)\n",
    "similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237322,)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import compute_reward\n",
    "\n",
    "rewards = compute_reward(similarities)\n",
    "rewards.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    237322.000000\n",
       "mean          0.455373\n",
       "std           1.590128\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           0.000000\n",
       "max          89.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(rewards).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Woman's essential \"nature\" : a classical, comm...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Unbearable Coldness of Female Being: Women...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Becoming an academic: Writing the self via Fou...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Also about Creative Motive in\"Wild Grass\"by Lu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perspektif Muhammad Sa‘Îd Al-Asymâwî tentang H...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237317</th>\n",
       "      <td>Abortion: what is the good? : developing a dee...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237318</th>\n",
       "      <td>Music, Mind, and Morality: Arousing the Body P...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237319</th>\n",
       "      <td>Autonomy, taking one's choices to be good, and...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237320</th>\n",
       "      <td>Particularism and pleasure\\nBook synopsis: Par...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237321</th>\n",
       "      <td>On the Structure of Rationality in the Thought...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237322 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  reward\n",
       "0       Woman's essential \"nature\" : a classical, comm...     1.0\n",
       "1       The Unbearable Coldness of Female Being: Women...     0.0\n",
       "2       Becoming an academic: Writing the self via Fou...     0.0\n",
       "3       Also about Creative Motive in\"Wild Grass\"by Lu...     0.0\n",
       "4       Perspektif Muhammad Sa‘Îd Al-Asymâwî tentang H...     0.0\n",
       "...                                                   ...     ...\n",
       "237317  Abortion: what is the good? : developing a dee...     0.0\n",
       "237318  Music, Mind, and Morality: Arousing the Body P...     0.0\n",
       "237319  Autonomy, taking one's choices to be good, and...     0.0\n",
       "237320  Particularism and pleasure\\nBook synopsis: Par...     0.0\n",
       "237321  On the Structure of Rationality in the Thought...     1.0\n",
       "\n",
       "[237322 rows x 2 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import prepare_data\n",
    "\n",
    "data = prepare_data(data, rewards)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import load_data\n",
    "\n",
    "batch_size = 128\n",
    "train_loader, test_loader, val_loader = load_data(\n",
    "    data, tokenizer, batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sft(data, model_name, load=False, save=True):\n",
    "    if load:\n",
    "        model = AutoModelForCausalLM.from_pretrained(\"../models/sft\")\n",
    "        return model\n",
    "    trainer = SFTTrainer(\n",
    "        model_name,\n",
    "        train_dataset=data,\n",
    "        dataset_text_field=\"text\",\n",
    "        max_seq_length=512,\n",
    "    )\n",
    "    trainer.train()\n",
    "    if save:\n",
    "        trainer.model.save_pretrained(\"../models/sft\")\n",
    "    return trainer.model\n",
    "\n",
    "sft_model = train_sft(data, model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rl(data, model_name, rewards, load=False, save=True):\n",
    "    if load:\n",
    "        model = torch.load(\"../models/rl.pt\")\n",
    "        return model\n",
    "    config = {\"batch_size\": 16}\n",
    "    ppo_trainer = PPOTrainer(\n",
    "        config, model, tokenizer=tokenizer,\n",
    "    )\n",
    "    if save:\n",
    "        torch.save(trainer.model, \"../models/rl.pt\")\n",
    "    return trainer.model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SFT + RL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at EleutherAI/pythia-70m-deduped were not used when initializing GPTNeoXForSequenceClassification: ['embed_out.weight']\n",
      "- This IS expected if you are initializing GPTNeoXForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPTNeoXForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at EleutherAI/pythia-70m-deduped and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 1/11867 [00:19<62:43:20, 19.03s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[179], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m         torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), \u001b[39m\"\u001b[39m\u001b[39m../models/rm.pt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[0;32m---> 25\u001b[0m r_model \u001b[39m=\u001b[39m train_r(r_model, train_loader)\n",
      "Cell \u001b[0;32mIn[179], line 18\u001b[0m, in \u001b[0;36mtrain_r\u001b[0;34m(model, data_loader, load, save)\u001b[0m\n\u001b[1;32m     16\u001b[0m     outputs \u001b[39m=\u001b[39m model(input_ids, attention_mask\u001b[39m=\u001b[39mattention_mask, labels\u001b[39m=\u001b[39mlabels)\n\u001b[1;32m     17\u001b[0m     loss \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mloss\n\u001b[0;32m---> 18\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     19\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     20\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m, Loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/pragmatic-reward-modeling/env/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/pragmatic-reward-modeling/env/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "r_model = GPTNeoXForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=1,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "def train_r(model, data_loader, save=None):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    n_epochs = 10\n",
    "    for epoch in tqdm(range(n_epochs), total=n_epochs):\n",
    "        for batch in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n",
    "    if save:\n",
    "        torch.save(model.state_dict(), save)\n",
    "    return model\n",
    "\n",
    "r_model = train_r(r_model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_r(model, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RM + RL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SFT + RM + RL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_survey(model, questions, options):\n",
    "    responses = []\n",
    "    for question, option in zip(questions, options):\n",
    "        response = []\n",
    "        for o in option:\n",
    "            prompt = f\"Question: {question}\\nAnswer: {o}\"\n",
    "            input_ids = model.tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "            with torch.no_grad():\n",
    "                loss = -model.model(input_ids, labels=input_ids).loss.item()\n",
    "                response += [loss]\n",
    "        response = torch.tensor(response)\n",
    "        probabilities = torch.softmax(response, dim=0).tolist()\n",
    "        responses += [probabilities]\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = {\n",
    "    \"Base\": base_model,\n",
    "    \"SFT\": sft_model,\n",
    "    \"RL\": rl_model,\n",
    "    \"SFT+RL\": sft_rl_model,\n",
    "    \"RM\": r_model,\n",
    "    \"RM+RL\": r_rl_model,\n",
    "    \"SFT+RM+RL\": sft_r_rl_model,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_responses = {}\n",
    "for model_type in model_types:\n",
    "    model = model_types[model_type]\n",
    "    model_response = answer_survey(model, questions, options)\n",
    "    model_responses[model_type] = model_response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_accuracy(model_responses, philosopher_responses):\n",
    "    accuracy = 0\n",
    "    for model_response, philosopher_response in zip(model_response, philosopher_responses):\n",
    "        if torch.argmax(torch.tensor(model_response)) == torch.argmax(torch.tensor(philosopher_response)):\n",
    "            accuracy += 1\n",
    "    accuracy / len(model_responses)\n",
    "    return accuracy\n",
    "\n",
    "accuracies = {}\n",
    "for model, model_response in model_responses.items():\n",
    "    accuracy = measure_accuracy(model_response, responses)\n",
    "    accuracies[model_type] = accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_divergence(model_responses, philosopher_responses):\n",
    "    kl_divergence = [entropy(mr, r) for mr, r in zip(model_responses, philosopher_responses)]\n",
    "    return kl_divergence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_correlation(questions, options, responses, question_pairs, option_pairs, response_tables):\n",
    "    for i, question_pair in enumerate(question_pairs):\n",
    "        for j, question in enumerate(questions):\n",
    "            if question_pair[0] in question:\n",
    "                break\n",
    "        for k, question in enumerate(questions):\n",
    "            if question_pair[1] in question:\n",
    "                break\n",
    "        response_a = options[j].index(option_pairs[i][0])\n",
    "        a = int(response_a == responses[j].index(max(responses[j])))\n",
    "        response_b = options[k].index(option_pairs[i][1])\n",
    "        b = int(response_b == responses[k].index(max(responses[k])))\n",
    "        k = a + b + int(a > 0)\n",
    "        probability = response_tables[i][k] / sum(response_tables[i])\n",
    "        probabilities += [probability]\n",
    "    return np.mean(probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
